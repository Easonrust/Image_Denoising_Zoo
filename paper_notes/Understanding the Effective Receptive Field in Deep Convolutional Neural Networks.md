# Understanding the Effective Receptive Field in Deep Convolutional Neural Networks

本文主要分析了 CNN 网络中的 Receptive Field，发现实际有效的感受野和理论上的感受野差距比较大，实际有效的感受野是一个高斯分布。

理论感受野可以大于原图，但有效的感受野一般都小于原图尺寸，另一个有意思的地方是有效感受野的大小经过训练之后是可以变大的，论文中有实验表明。

这篇文章中的感受野定义：在卷积神经网络CNN中，决定某一层输出结果中一个元素所对应的输入层的区域大小，被称作感受野receptive field。

> 博客园上一个比较容易理解的概念：在卷积神经网络CNN中，决定某一层输出结果中一个元素所对应的输入层的区域大小，被称作感受野receptive field。



**感受野是考量feature map中每个神经元具有多少全局性的一个重要指标**



一种计算感受野的方法：

![image-20200318204352787](https://tva1.sinaimg.cn/large/00831rSTly1gcyd8p95d3j315u0h8tc8.jpg)

增加感受野的操作：

* 增加网络的层数，加深网络深度。理论上可以线性地增大感受野，每一层产生的感受野的增量为卷积核的大小。
* 下采样: 下采样可以成倍地增大感受野。
*  dilate ：dilate操作可以成倍地增大感受野

# Convolutional Pose Machines

三种增大感受野的方法：

- 增加pooling层，但是会降低准确性）
- 增大卷积核的kernel size，但是会增加参数
- 增加卷积层的个数，但是会面临梯度消失的问题

CPM中作者用的增加卷积层个数的方法来增加感受野，但是他用多阶段训练的方式并引入中间层监督的方法来解决梯度消失的问题。

1. pooling增加感受野的原因：首先它第一个作用是降低feature map的尺寸，减少需要训练的参数；其次，因为有缩小的作用，所以之前的4个像素点，现在压缩成1个。那么，相当于我透过这1个点，就可以看到前面的4个点，这不就是把当前map的感受野一下子放大了

   >  https://blog.csdn.net/jiachen0212/article/details/78548667

   然而pooling操作会造成信息损失

2. 带洞卷积

### 多尺度模型

> https://zhuanlan.zhihu.com/p/74710464

所谓多尺度，实际上就是对**信号的不同粒度的采样**，通常在不同的尺度下我们可以观察到不同的特征，从而完成不同的任务。

主要是图像金字塔和特征金字塔两种方案，但是具体的网络结构可以分为以下几种：(1) 多尺度输入。(2) 多尺度特征融合。(3) 多尺度特征预测融合。(4) 以上方法的组合。

- 多尺度输入

  就是使用**多个尺度的图像输入(图像金字塔)**，然后将其结果进行融合，传统的人脸检测算法**V-J框架**就采用了这样的思路。

  深度学习中模型以MTCNN[1]人脸检测算法为代表，其流程如下，在第一步检测PNet中就使用了多个分辨率的输入，各个分辨率的预测结果(检测框)一起作为RNet的输入。

  ![image-20200318205834116](/Users/leyang/Library/Application Support/typora-user-images/image-20200318205834116.png)

- 多尺度特征融合

  - 并行多分支

    Inception基本模块

    带孔卷积控制感受野

    直接使用不同大小的池化操作，被PSPNet[4]采用。

  - 串行多分支

    U-Net为代表，需要通过**跳层连接**来实现特征组合，这样的结构在图像分割/目标检测任务中是非常常见的。

- 多尺度特征预测融合

  即在**不同的特征尺度进行预测**，最后将结果进行融合，以目标检测中的SSD[7]为代表。

  SSD在不同stride不同大小的特征图上进行预测。低层特征图stride较小，尺寸较大，感受野较小，期望能检测到小目标。高层特征图stride较大，尺寸较小，感受野较大，期望能检测到大目标。

- 即将高层的特征添加到相邻的低层组合成新的特征，每一层单独进行预测。当然，也可以反过来将低层的特征也添加到高层，