We adopted well-known performance metrics, such as accuracy (Acc), precision (Pre), sensitivity (Sen), specificity (Spe) and F1, to evaluate our model. Among them, accuracy, which is defined as the ratio of the number of samples correctly classified to the total number of samples, is amongst the most commonly used metrics in the literature. The definitions of the adopted performance metrics are as follows:
$$
\begin{align*}
 &Acc=\frac{TP+TN}{TP+TN+FP+FN} \\
 &Pre=\frac{TP}{TP+FP}\\
 &Sen=\frac{TP}{TP+FN}\\
 &Spe=\frac{TN}{FP+TN}\\
 &F1=\frac{2 \times Pre \times Sen}{Pre + Sen}
\end{align*}
$$
TP (true positive) is the number of the EEG records which are abnormal and actually indentified as abnormal; TN (true negative) is the number of the EEG records which are normal and actually identified as normal; FP (false positive) is the number of the EEG records which are normal but are actually predicted as abnormal; and FN (false negative) is the number of the EEG records which are abnormal but are actually predicted as normal.

In order to reduce the statistical uncertainty of test error estimation because of the small-scale test datasets, we used 10-fold cross-validation for evaluation. That is, We randomly divided the 2300 EEG signals of each category into ten nonoverlapping folds. During the i-th test, the i-th fold of the EEG signals is used for testing while the other 9 folds are used for training. The accuracy, sensitivity and specificity values which are reported in this paper are the average values among the results of ten evaluations.